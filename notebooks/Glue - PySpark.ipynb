{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9b959a-69aa-4809-8b35-f1f3d26386a2",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37dcb26e-d4fe-4215-b1c6-c211a7171e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.transforms import *\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4bc0fc-c277-477b-8cdc-b8ee4c654651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "S3_MOCK_ENDPOINT = \"http://localstack:4566\"\n",
    "BUCKET = 'glue-bucket'\n",
    "\n",
    "# Values do not really matter\n",
    "ACCESS_KEY = \"mock\"\n",
    "SECRET_KEY = \"mock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87f61b5-250b-47a0-bf2a-c6ccc48ef879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glueContext = GlueContext(SparkContext.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b28bf2-e108-460f-a208-80cd1374f095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create spark session and configure S3A for writing to S3\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "hadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.path.style.access\", \"true\")\n",
    "hadoop_conf.set(\"fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "hadoop_conf.set(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", ACCESS_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", SECRET_KEY)\n",
    "hadoop_conf.set(\"fs.s3a.session.token\", \"mock\")\n",
    "hadoop_conf.set(\"fs.s3a.endpoint\", S3_MOCK_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c1184-a341-4460-81db-3da2bb78d616",
   "metadata": {},
   "source": [
    "# Glue example \n",
    "\n",
    "Taken from https://aws.amazon.com/blogs/big-data/building-an-aws-glue-etl-pipeline-locally-without-an-aws-account/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0a0f56-7b45-4756-9d0a-25ab13a0065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<awsglue.dynamicframe.DynamicFrame object at 0x7fef6a868e10>"
     ]
    }
   ],
   "source": [
    "\n",
    "order_list = [\n",
    "    ['1005', '623', 'YES', '1418901234', '75091'], \\\n",
    "    ['1006', '547', 'NO', '1418901256', '75034'], \\\n",
    "    ['1007', '823', 'YES', '1418901300', '75023'], \\\n",
    "    ['1008', '912', 'NO', '1418901400', '82091'], \\\n",
    "    ['1009', '321', 'YES', '1418902000', '90093'] \\\n",
    "    ]\n",
    "\n",
    "\n",
    "# Define schema for the order_list\n",
    "order_schema = StructType([\n",
    "    StructField(\"order_id\", StringType()),\n",
    "    StructField(\"customer_id\", StringType()),\n",
    "    StructField(\"essential_item\", StringType()),\n",
    "    StructField(\"timestamp\", StringType()),\n",
    "    StructField(\"zipcode\", StringType())\n",
    "])\n",
    "\n",
    "# Create a Spark Dataframe from the python list and the schema\n",
    "df_orders = spark.createDataFrame(order_list, schema=order_schema)\n",
    "\n",
    "dyf_orders = DynamicFrame.fromDF(df_orders, glueContext, \"dyf\")\n",
    "\n",
    "# Input \n",
    "dyf_applyMapping = ApplyMapping.apply(frame=dyf_orders, mappings=[\n",
    "    (\"order_id\", \"String\", \"order_id\", \"Long\"),\n",
    "    (\"customer_id\", \"String\", \"customer_id\", \"Long\"),\n",
    "    (\"essential_item\", \"String\", \"essential_item\", \"String\"),\n",
    "    (\"timestamp\", \"String\", \"timestamp\", \"Long\"),\n",
    "    (\"zipcode\", \"String\", \"zip\", \"Long\")\n",
    "])\n",
    "\n",
    "\n",
    "def next_day_air(rec):\n",
    "    if rec[\"zip\"] == 75034:\n",
    "        rec[\"next_day_air\"] = True\n",
    "    return rec\n",
    "\n",
    "\n",
    "mapped_dyF = Map.apply(frame=dyf_applyMapping, f=next_day_air)\n",
    "\n",
    "glueContext.write_dynamic_frame.from_options(\n",
    "    frame=mapped_dyF,\n",
    "    connection_options={'path': f's3a://{BUCKET}/output'},\n",
    "    connection_type='s3',\n",
    "    format='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0dc86-c934-40bc-9d12-1fbb75246005",
   "metadata": {},
   "source": [
    "# Browse output using Boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e43466b-d8ce-4c86-ad84-a1588e953ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create connection to S3\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    region_name=\"eu-central-1\",\n",
    "    endpoint_url=S3_MOCK_ENDPOINT,\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e124d8-fc8d-4c93-9585-1f58e91019a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/run-1649940782552-part-r-00000\n",
      "output/run-1649942603534-part-r-00000"
     ]
    }
   ],
   "source": [
    "# List items in bucket\n",
    "response = s3.list_objects(Bucket=BUCKET)\n",
    "for item in response['Contents']:\n",
    "    print(item['Key'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue Spark - Local (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
